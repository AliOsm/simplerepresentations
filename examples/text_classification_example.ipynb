{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleRepresentations Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfIZzlQgsQcp",
        "colab_type": "text"
      },
      "source": [
        "### 1- Check GPU type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi7M9TxnVIm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rzxUzRxsZBy",
        "colab_type": "text"
      },
      "source": [
        "### 2- Install SimpleRepresentations library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L_bOf4Aairf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install simplerepresentations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmFYTTY-sgm2",
        "colab_type": "text"
      },
      "source": [
        "### 3- Download the Large Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3OHokesaqe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar xzf aclImdb_v1.tar.gz\n",
        "!rm aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnD8mqqLszur",
        "colab_type": "text"
      },
      "source": [
        "### 4- Load train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvrU64qu3WGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "TRAIN_POS_PATH = 'aclImdb/train/pos'\n",
        "TRAIN_NEG_PATH = 'aclImdb/train/neg'\n",
        "TEST_POS_PATH  = 'aclImdb/test/pos'\n",
        "TEST_NEG_PATH  = 'aclImdb/test/neg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fqbDstqcbIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of Train/Positive examples:', len(os.listdir(TRAIN_POS_PATH)))\n",
        "print('Number of Train/Negative examples:', len(os.listdir(TRAIN_NEG_PATH)))\n",
        "print('Number of Test/Positive examples:', len(os.listdir(TEST_POS_PATH)))\n",
        "print('Number of Test/Negative examples:', len(os.listdir(TEST_NEG_PATH)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmWp_DvocsRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_files(dir_path):\n",
        "    data = list()\n",
        "    for file in os.listdir(dir_path):\n",
        "        with open(os.path.join(dir_path, file), 'r') as file:\n",
        "            data.append(file.readlines()[0].strip())\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcQL0YfIdzSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pos_examples = load_files(TRAIN_POS_PATH)\n",
        "train_neg_examples = load_files(TRAIN_NEG_PATH)\n",
        "test_pos_examples = load_files(TEST_POS_PATH)\n",
        "test_neg_examples = load_files(TEST_NEG_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTdiFRka2ars",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_examples = train_pos_examples + train_neg_examples\n",
        "train_labels = ([1] * len(train_pos_examples)) + ([0] * len(train_neg_examples))\n",
        "train_data = list(zip(train_examples, train_labels))\n",
        "random.shuffle(train_data)\n",
        "train_examples, train_labels = zip(*train_data)\n",
        "train_examples = list(train_examples)\n",
        "train_labels = list(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNpganA2_R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_examples = test_pos_examples + test_neg_examples\n",
        "test_labels = ([1] * len(test_pos_examples)) + ([0] * len(test_neg_examples))\n",
        "test_data = list(zip(test_examples, test_labels))\n",
        "random.shuffle(test_data)\n",
        "test_examples, test_labels = zip(*test_data)\n",
        "test_examples = list(test_examples)\n",
        "test_labels = list(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyAjELyos8KP",
        "colab_type": "text"
      },
      "source": [
        "### 5- Define SimpleRepresentations model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_FFJah-ecih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simplerepresentations import RepresentationModel\n",
        "\n",
        "model_type = 'roberta'\n",
        "model_name = 'roberta-base'\n",
        "\n",
        "representation_model = RepresentationModel(\n",
        "    model_type=model_type,\n",
        "    model_name=model_name,\n",
        "    batch_size=128,\n",
        "    max_seq_length=128, # truncate sentences to be less than or equal to 128 tokens\n",
        "    combination_method='sum', # sum the last `last_hidden_to_use` hidden states\n",
        "    last_hidden_to_use=1, # use the last 1 hidden states to build tokens representations\n",
        "    verbose=0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXMfETQXKwqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_sentences_representations, all_tokens_representations = representation_model(['Simple Representations!'])\n",
        "\n",
        "print(all_sentences_representations.shape) # (1, 768)\n",
        "print(all_tokens_representations.shape) # (1, 128, 768)\n",
        "print(all_sentences_representations[0].shape) # (768,)\n",
        "print(all_tokens_representations[0].shape) # (128, 768)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5bcA8GmxUNv",
        "colab_type": "text"
      },
      "source": [
        "### 6- Define data generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uE2PCcCwh0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, representation_model, sentences, labels, batch_size, token_level=True):\n",
        "        self.representation_model = representation_model\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.token_level = token_level\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.sentences) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentences_batch = np.array(self.sentences[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
        "        labels_batch = np.array(self.labels[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
        "\n",
        "        sentences_sen_batch, sentences_tok_batch = self.representation_model(sentences_batch)\n",
        "\n",
        "        if self.token_level:\n",
        "            sentences_batch = sentences_tok_batch\n",
        "        else:\n",
        "            sentences_batch = sentences_sen_batch\n",
        "\n",
        "        return sentences_batch, np.array(labels_batch)\n",
        "\n",
        "train_tok_generator = DataGenerator(representation_model, train_examples, train_labels, 128)\n",
        "test_tok_generator = DataGenerator(representation_model, test_examples, test_labels, 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9LK8H6GtFlV",
        "colab_type": "text"
      },
      "source": [
        "### 7- Define token level recurrent neural network for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb2omlBAfp7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Input, Model\n",
        "from keras.layers import Dropout, Dense, LSTM, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model_input = Input(shape=(128, len(representation_model(['test'])[0][0])))\n",
        "\n",
        "model = Bidirectional(\n",
        "            LSTM(\n",
        "                units=128,\n",
        "                dropout=0.3,\n",
        "                return_sequences=True\n",
        "            )\n",
        "        )(model_input)\n",
        "model = Bidirectional(\n",
        "            LSTM(\n",
        "                units=128,\n",
        "                dropout=0.3,\n",
        "                return_sequences=False\n",
        "            )\n",
        "        )(model)\n",
        "model = Dense(128, activation='relu')(model)\n",
        "model = Dropout(0.3)(model)\n",
        "\n",
        "model_output = Dense(1, activation='sigmoid')(model)\n",
        "\n",
        "model = Model(model_input, model_output)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsmHEBIv1ctN",
        "colab_type": "text"
      },
      "source": [
        "### 8- Train token level model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p11lJng1bvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_tok_generator, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FFFkzpa_hi0",
        "colab_type": "text"
      },
      "source": [
        "### 9- Evaluate token level model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEA51UqM-8Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.evaluate_generator(test_tok_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}